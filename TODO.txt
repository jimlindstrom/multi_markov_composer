### QUESTIONS #################################################################

Why are so few of the improvised melodies rhythmically unintelligable?

### NEW CRITICS ###############################################################

How could we create critics that tie rhythmic and pitch information together? 
	- If the current note is relatively long, that may cause human 
	  listeners to perceive a phrase boundary. It may, therefore, be a good
	  good idea to flatten out the distribution of expectations for the 
	  next pitch.
	- Similarly, if you've got very strong pitch expectations (low entropy),
	  that may suggest a nice long end-of-phrase duration.
	- Perhaps the PitchAndPitchClassSetCritic could be improved by 
	  including a metric strength factor (2 for first beat of measure, 1
	  for all other beats, 0 for subbeats).

Perhaps we could explicitly model listener surprise/boredom and use that as a
symbol in critics.
	- This might help avoid overly bland sequences.
	- Start with a model that takes a time-series of surprise values and
	  outputs a discrete state, such as: normal (anything's fine), bored 
	  (wants more surprise), recovering (doesn't want any surprise). The 
	  response curve timing would need to be optimized by trial and error.

Whenever the piece is in an expository phase (developing new material), there
should be a critic that ensures the chunks are intelligible (not too long, 
clearly demarkated, statistically differentiated).  How to do that?
	- And actually this gets at an interesting point. There are certain
	  free parameters in a composition that are like hidden markov 
	  states--they are not directly observable, but can be estimated from
	  the observable. Meter and beat position are two. Pitch class sets are
	  another. 
	- Right now the codebase is kind of sneakily analyzing meter and 
	  pitch class, versus treating them as first-class properties. Likewise
	  the code currently instantiates meter explicitly, but does not do so 
	  for pitch class set. I think that the composer should model not only
	  these properties more explicitly, but also superstructure. 
	- I would also want some sort of penalty (akin to boredom) for when a 
	  song doesn't exhibit any self-similarity and longer-term structure.

### BETTER IMPROVS ############################################################

- Why is the ComplexDurationCritic so surprised whenever there's a longer note? 
-- INV: Are quarter notes being treated the same across all meters?
-- I want to capture rythmic periodicity. It shouldn't be so surprising to see long notes at the same beat position every few measures. What about using a within-song suffix structure to create samae-song, longer-term expectations?
-- What about using phrase detection? After the first phrase or two (which are set off by demarcation--long notes, big surprises, etc), subsequent ones are usually going to be seen by cross-similarity (e.g., the same length, similar notes/durations).
--Is it the case that surprise is minimized at ends of phrases? Strong pressure for antecedent resolution? 

### CALL-AND-RESPONSE ##########################################################

Use copies of the critics that are trained on the stats in the stimulus.  That way the response should be more likely to bear a resemblance to the stimulus and it should feel more interactive.

How can the improvs contain repeated motifs?
	- use two copies of every critic.  One is trained on long-term inputs.  The
	  other is reset at the beginning of each listening, and is used to generate
	  piece-specific expectations
	- generate ad hoc, instead of rigidly left-to-right?
	- add motif critic that looks for good places to insert these motifs and
	  creates expectations for them

Manage the surprise:
	- Try constraining the surprises primarily to either pitch OR rhythm.  Could 
	  do this by self-multiplying expectations, to square the probabilities
	- Have a surprise critic that generates expected surprise envelopes

Do a better job baselining the predictive performance and then measuring 
improvements:
	- Look at the cross entropy coming out of the pitch generator, in addition
	  to the individual critics.  That is more representative of the whole
	  model, and the likely cross entropy of generated improvs.
	- Move from cumulative information content to cumulative cross entropy, which
	  is a more standard info-theoretic calculation.

Look at aggregate stats:
	- pitch range
	- jumps vs. steps
	- surprise envelopes
	- overall shape of line 

Explore ways to make it harmonically intelligible
	- critic for {pitch class set (polyphonic, harmonic context); last note}->{next note}
		- this critic would be idle/mute for monophonic inputs
		- this is easier in 4-part choral-style midi files, because they're separated into
		  tracks.  In the general case (live, human performer), we'd need a stream
		  splitter.  Could be a fancier one that can parse things like Bach prelude 1. Or
		  could just take the highest active note at any point in time.
	- Like duration, if we have notes from other tracks, we can use that as polyphonic
	  context. If we don't, we could fall back on scalar context.

Have PitchAndPitchClassSetCritic do more sophisticated weighting, based on 
	- beat strength

Change to planning based on time or number of beats (vs. number of notes)

I'd like to build layers of assumptions and fall-back as needed.
	- First assume we're doing standard Western cannon.  
	- Then if that fails, assume there's still chords and scales.  
	- Then if that fails, look for consistent pitch class sets.  
	- And if all else fails ... no idea.

### REFACTORING ###############################################################

fake_sensor_vectors is now huge.  figure out a different strategy...
	- Don't load all >50MB of events when running specs
	- I also want to load / not load different styles easily.

Put a 'context' member on each note that points to shared context hash (***)
	- this could be different for different phrases
	- it could contain harmonic info, intended surprise levels, etc.

### MORE RESPONSIVE / INTERACTIVE #############################################

Mimic the stimulus's: meter
Mimic the stimulus's: phrase length
Mimic the stimulus's: tempo
Mimic the stimulus's: pitch classes

### INTRODUCING FARG ARCHITECTURE #############################################

Explore FARG architecture for improvising better endings

Use rule-based FARG architectures to go apply happiness / unhappiness values throughout a finished improv and rip the parts

Use FARG techniques to look for structure / repeated patterns in the stimulus

################################################################################################################
################################################################################################################
################################################################################################################

### Objecive ##################################################################

NO: Structurally segment the melody into a decomposable tree
	- this is not what I am trying to do.  I don't believe that every note
	  must fulfill a structural role.  I believe that the ear is retaining 
	  enough information to make that calculation.  I believe that the lay 
	  ear reduces information pretty radically and hears approximate contours
	  (envelopes), fuzzy intervals, etc.  

YES: Identify repeated elements or groups of elements.
	- This is more what I'm after.  I believe that the note-by-note stats
	  that are currently driving the improv engine are insufficient to 
	  structure the piece.  I'm merely looking for some top-level templates
	  that can be used as a skeleton to exert top-down structure pressure on
	  the bottom-up, note-by-note statistics currently being used to generate
	  improvisations

### How to represent notes ####################################################

Pour more analysis (symbols) back into the notes themselves:
	- qIOI
	- fuzzy qIOI (short / med / long)
	- pitch
	- pitch class
	- pitch class distance (along circle of 5ths)
	- index in pitch class set
	- interval 
	- fuzzy interval (direction & step/jump)
and use these dimensions to compare similarity / role 

### Architecture ##############################################################

What does a group look like?  
	- Just an array?
	- A list of slots/roles?
	- Maybe groups start out as arrays, but can get promoted into themes, which
	  describe the role of each item in the array, or describe how each item is
	  related to the one before it, or both. (promotion to themes would occur when
	  two groups are being compared/related.)

What does a group represent?
	- some sense of entity/oneness/unity:
	- gestalt principles (separated by rests; in a different range; texturally 
	  unique)
	- constraints (a single pitch class set; only quarter notes; etc)
	- a repeated pattern

What do successive instances of a group represent?
	- variation
		- variations on an underlying, hidden, but stationary archetype (theme)?
	- development
		- http://en.wikipedia.org/wiki/Musical_development
		- http://en.wikipedia.org/wiki/Sonata_form
	- developing variation
		- evolutions/changes (complications/extensions/complixifications) of an 
		  intial simple idea?
		- variations are produced through the development of existing material
		- http://en.wikipedia.org/wiki/Developing_variation

Correspondences between groups may not be strictly top-down, decompositional
	- Maybe motifs, themes get labeled and a copy is put on a shelf, and then
	  new instances get the same label, with a new instance ID.  There could
	  be a new theme composed of a previous theme, plus a variation of an old
	  motif, plus a new motif. 
	- Things only get labeled as motifs, themes when they're seen a second 
	  time?

### Heuristics for grouping / splitting #######################################

Split groupings at
	- moments of high surprise

Split groupings at
	- the beginning or end of long IOIs
	- bar lines

Gestalt principles (look to GTTM for more)
	- similarity - in A.A.B, prefer to group A.A vs A.B
	- proximity - in A.B..C, prefer to group A.B vs. B..C
	- closure - ABC.D is more likely a group than is ABC.A 
	- good continuation - A.BxCy.z should produce overlapping A.B.C and x.y.z
	- common fate - AxyBxyCxyD should produce interleaved A..B..C..D and xy.xy.xy ??
	- good form - ?

Groups should be homogeneous:
	- Groups at a given abstraction-height should all have similar length
	- Groups at different heights should have lengths in mostly non-overlapping 
	  ranges

